# Text Generator
 The repository contains code to generate text based on the previous sequence data. The model uses GRU (gated recurrent unit) layers. It predicts character by character the new sequence.
 
The Folder, <b>Text Generator</b> contains a more generalized code which is independent of the language. 
An example of it shown with the help of the language Hindi.

A pre trained model weights are saved under saved_model.
The data is stored in the Data folder in txt format. 


 
